[TOC]


# KNN（K- nearest neighbor）算法实践
&emsp KNN算法实践总共包括三个部分，第一部分为KNN算法说明及基本实现，主要说明算法思想，并且用python实现了此算法。第二三部分主要是KNN 的算法实践的两个案例，重点在于对数据进行预处理。 在此过程中运用了numpy科学运算包。
# >kNN算法说明及基本实现
## kNN算法说明
  &emsp k近邻法(k-nearest neighbor, k-NN)是1967年由Cover T和Hart P提出的一种基本分类与回归方法。它的工作原理是：存在一个样本数据集合，也称作为训练样本集，并且样本集中每个数据都存在标签，即我们知道样本集中每一个数据与所属分类的对应关系。输入没有标签的新数据后，将新的数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本最相似数据(最近邻)的分类标签。一般来说，我们只选择样本数据集中前k个最相似的数据，这就是k-近邻算法中k的出处，通常k是不大于20的整数。最后，选择k个最相似数据中出现次数最多的分类，作为新数据的分类.

KNN算法步骤
>
1 > 1 计算已知类别数据集中的点与当前点之间的距离；(欧式距离)
2 > 2 按照距离递增次序排序；
3 > 3 选取与当前点距离最小的k个点；
4 > 4 确定前k个点所在类别的出现频率；
5 > 5 返回前k个点所出现频率最高的类别作为当前点的预测分类。
>

## 代码实践
'代码在kNN.py中，附有注释'
&emsp 
# >KNN算法实践1 约会网站配对效果改进
# >KNN算法实践2 手写数字识别
